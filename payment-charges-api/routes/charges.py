from flask import Blueprint, request, jsonify
from repository.database import db
from db_models.charges import Charge, ChargeStatus
from datetime import datetime
import uuid
from infrastructure.redis_client import redis_client
import json

from audit.logger import logger

charges_bp = Blueprint("charges", __name__)


@charges_bp.route("/payment/charges", methods=["POST"])
def create_charge():
    # NOTE: Keep HTTP layer thin: validate basic request shape and delegate business rules to service layer
    # (In this project, logic is still here for simplicity, but the intention is clear.)
    data = request.get_json()

    # Basic validation: ensure required fields exist and are valid
    if not data or "value" not in data:
        return jsonify({"error": "Value is required"}), 400

    if data["value"] <= 0:
        return jsonify({"error": "Invalid value"}), 400

    # Charges start as PENDING. Payment confirmation must happen asynchronously via webhook.
    charge = Charge(
        value=data["value"],
        status=ChargeStatus.PENDING,
        external_id=str(uuid.uuid4()),  # Public identifier shared with the bank / external systems
        created_at=datetime.utcnow(),
    )

    db.session.add(charge)
    db.session.commit()

    # Redis TTL acts as the "source of truth" for charge expiration:
    # - If the TTL key expires, a PENDING charge becomes EXPIRED on next read (lazy expiration).
    # - This avoids periodic cron jobs and keeps expiration logic consistent across services.
    redis_client.setex(
        f"charge:ttl:{charge.external_id}",
        1800,  # 30 minutes
        "PENDING",
    )

    # Structured log: keeps operational traceability (request_id injected by LoggerAdapter)
    logger.info(
        f"Charge created | charge_id={charge.id} | external_id={charge.external_id}"
    )

    return jsonify({
        "id": charge.id,
        "external_id": charge.external_id,
        "status": charge.status,
    }), 201


@charges_bp.route("/payment/charges/<int:charge_id>", methods=["GET"])
def get_charge(charge_id):
    # Read-through caching: speed up repeated reads of the same charge for short periods.
    # IMPORTANT: Cache is treated as ephemeral â€” DB remains the persistent store.
    cache_key = f"charge:{charge_id}"

    cached = redis_client.get(cache_key)
    if cached:
        # Cached payload is JSON encoded; return it directly to avoid unnecessary DB hits.
        return jsonify(json.loads(cached))

    charge = Charge.query.get(charge_id)
    if not charge:
        return jsonify({"error": "Charge not found"}), 404

    ttl_key = f"charge:ttl:{charge.external_id}"

    # Lazy expiration strategy:
    # If the TTL key no longer exists and the charge is still PENDING, we mark it EXPIRED.
    # This ensures the API reflects expiration without relying on background schedulers.
    if not redis_client.exists(ttl_key):
        if charge.status == ChargeStatus.PENDING:
            charge.status = ChargeStatus.EXPIRED
            db.session.commit()
            # Invalidate cache (if any) to avoid serving stale state after status transition.
            redis_client.delete(cache_key)

    response = {
        "id": charge.id,
        "value": charge.value,
        "status": charge.status,
        # Optional: expires_at could be derived if you store created_at + TTL, but Redis TTL is the authority here.
    }

    # Short TTL cache to reduce load under read bursts (e.g., polling clients).
    redis_client.setex(
        cache_key,
        60,  # cache for 60 seconds
        json.dumps(response),
    )

    return jsonify(response)

